{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0obdda_siHjI",
        "outputId": "94e417d8-1f4c-485b-dfba-d32aa6553fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "to_pil_image = transforms.ToPILImage()\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "!pip install wandb --quiet\n",
        "import wandb\n",
        "!pip install torchsummaryX -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wSKevbNYiPfC"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-b5a0I1586h",
        "outputId": "6df459ed-d88e-4158-cfbe-bd229ff62e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget -q\n",
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Si-ExmyX6APH",
        "outputId": "a211812d-327d-43a7-f917-eaac76c2cb5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bUN7NV7arMM8ASA2pTJ8hvdkc5N3qoJw\n",
            "To: /content/TrainingData.zip\n",
            "100%|██████████| 15.3G/15.3G [03:43<00:00, 68.5MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TrainingData.zip'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_file = \"TrainingData.zip\"\n",
        "gdown.download(\"https://drive.google.com/uc?id=1bUN7NV7arMM8ASA2pTJ8hvdkc5N3qoJw\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CHGbTxTm91nW"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/TrainingData.zip -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZewKn9lpDcHa"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/TrainDatasetFull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "732DBAFZDnVO",
        "outputId": "8640e630-9cb4-492d-dc9c-7b9f221e7fcf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/TrainDatasetFull/depth19'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "source_path = '/content/data/TrainingData/2n8kARJN3HM/depth20'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/2n8kARJN3HM_tilt/depth19'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f837TuXHEb4i",
        "outputId": "3cd75a33-7f50-47e4-a949-c736c99e4762"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/TrainDatasetFull/depth1'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_path = '/content/data/TrainingData/B6ByNegPMKs/depth18'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/B6ByNegPMKs_tilt/depth17'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/JeFG25nYj2p/depth16'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/JeFG25nYj2p_tilt/depth15'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/Matterport/depth14'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/Matterport_tilt/depth13'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/Vvot9Ly1tCj/depth12'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/Vvot9Ly1tCj_tilt/depth11'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/campus_01/depth10'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/campus_02/depth9'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/forest/depth8'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/garage/depth7'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/indoor/depth6'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/tunnel/depth5'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/ur6pFq6Qu1A/depth4'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/ur6pFq6Qu1A_tilt/depth3'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/vyrNrziPKCB/depth2'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)\n",
        "\n",
        "source_path = '/content/data/TrainingData/vyrNrziPKCB_tilt/depth1'\n",
        "destination_path = '/content/TrainDatasetFull'\n",
        "\n",
        "shutil.move(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "m9kSyjWHF6Yx"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/Generated_Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eBVEA6xyiXm6"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "to_pil_image = transforms.ToPILImage()\n",
        "def image_to_vid(images):\n",
        "    imgs = [np.array(to_pil_image(img)) for img in images]\n",
        "    imageio.mimsave('/content/Generated_Images', imgs)\n",
        "def save_reconstructed_images(recon_images, epoch):\n",
        "    save_image(recon_images.cpu(), f\"/content/Generated_Images/output{epoch}.jpg\")\n",
        "def save_loss_plot(train_loss, valid_loss):\n",
        "    # loss plots\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(train_loss, color='orange', label='train loss')\n",
        "    plt.plot(valid_loss, color='red', label='validataion loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/Generated_Images/loss.jpg')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gK-7qfMLi7W2"
      },
      "outputs": [],
      "source": [
        "def final_loss(bce_loss, mu, logvar):\n",
        "    BCE = bce_loss\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + 0.5 *KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "vkIXU2C7jPDW"
      },
      "outputs": [],
      "source": [
        "kernel_size = 10\n",
        "init_channels = 8\n",
        "image_channels = 3\n",
        "latent_dim = 512\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gUNYl5ped5Vj"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 2\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        self.SD = torchvision.ops.StochasticDepth( p = 0.15, mode = \"batch\")\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "\n",
        "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = self.SD(x)\n",
        "\n",
        "        #downsample if needed\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        #add identity\n",
        "        x += identity\n",
        "        x=self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    expansion = 2\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
        "      x = self.batch_norm2(self.conv2(x))\n",
        "\n",
        "      if self.i_downsample is not None:\n",
        "          identity = self.i_downsample(identity)\n",
        "\n",
        "      print(x.shape)\n",
        "      print(identity.shape)\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, ResBlock, layer_list, num_channels=3):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
        "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=256, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc_mu = nn.Linear(512, latent_dim)\n",
        "        self.fc_log_var = nn.Linear(512, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 512)\n",
        "\n",
        "    def forward(self, x, return_feats = False):\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "\n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "\n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lmnm1cMcXWYV"
      },
      "outputs": [],
      "source": [
        "class Reparam(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Reparam, self).__init__()\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc1 = nn.Linear(512, 512)\n",
        "    self.fc_mu = nn.Linear(512, latent_dim)\n",
        "    self.fc_log_var = nn.Linear(512, latent_dim)\n",
        "    self.fc2 = nn.Linear(latent_dim, 512)\n",
        "\n",
        "  def reparameterize(self, mu, log_var):\n",
        "        \"\"\"\n",
        "        :param mu: mean from the encoder's latent space\n",
        "        :param log_var: log variance from the encoder's latent space\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5*log_var) # standard deviation\n",
        "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
        "        sample = mu + (eps * std) # sampling\n",
        "        return sample\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch, _, _, _ = x.shape\n",
        "    x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
        "    hidden = self.fc1(x)\n",
        "    # get `mu` and `log_var`\n",
        "    mu = self.fc_mu(hidden)\n",
        "    log_var = self.fc_log_var(hidden)\n",
        "    # get the latent vector through reparameterization\n",
        "    z = self.reparameterize(mu, log_var)\n",
        "    z = self.fc2(z)\n",
        "    z = z.view(-1, 512, 1, 1)\n",
        "\n",
        "    return mu, log_var, z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lwJLrZ72IE7T"
      },
      "outputs": [],
      "source": [
        "x_encode = torch.rand(batch_size,image_channels,640,360)\n",
        "y = ConvEncoder(Bottleneck, layer_list=[2, 6, 8, 4]).to(device)\n",
        "# torchsummaryX.summary(y,x_encode.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WkBeKbwKkTq7"
      },
      "outputs": [],
      "source": [
        "class ConvDecoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvDecoder, self).__init__()\n",
        "    self.dec1 = nn.ConvTranspose2d(\n",
        "            in_channels=512, out_channels=256, kernel_size=(16,9),\n",
        "            stride=1, padding=0\n",
        "    )\n",
        "\n",
        "    self.dec2 = nn.ConvTranspose2d(\n",
        "        in_channels=256, out_channels=128, kernel_size=(19,12),\n",
        "        stride=3, padding=0\n",
        "    )\n",
        "\n",
        "\n",
        "    self.dec3 = nn.ConvTranspose2d(\n",
        "        in_channels=128, out_channels=64, kernel_size=(19,12),\n",
        "        stride=1, padding=1\n",
        "    )\n",
        "\n",
        "    self.dec4 = nn.ConvTranspose2d(\n",
        "        in_channels=64, out_channels=32, kernel_size=8,\n",
        "        stride=2, padding=3\n",
        "    )\n",
        "\n",
        "    self.dec5 = nn.ConvTranspose2d(\n",
        "        in_channels=32, out_channels=16, kernel_size=8,\n",
        "        stride=2, padding=3\n",
        "    )\n",
        "\n",
        "    self.dec6 = nn.ConvTranspose2d(\n",
        "        in_channels=16, out_channels=8, kernel_size=8,\n",
        "        stride=2, padding=3\n",
        "    )\n",
        "\n",
        "    self.dec7 = nn.ConvTranspose2d(\n",
        "        in_channels=8, out_channels=image_channels, kernel_size=3,\n",
        "        stride=1, padding=1\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.dec1(x))\n",
        "    x = F.relu(self.dec2(x))\n",
        "    x = F.relu(self.dec3(x))\n",
        "    x = F.relu(self.dec4(x))\n",
        "    x = F.relu(self.dec5(x))\n",
        "    x = F.relu(self.dec6(x))\n",
        "    reconstruction = torch.sigmoid(self.dec7(x))\n",
        "    return reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7bAJPFcS41Ku"
      },
      "outputs": [],
      "source": [
        "x_decode = torch.rand(batch_size,512,1,1)\n",
        "y = ConvDecoder().to(device)\n",
        "#torchsummaryX.summary(y,x_decode.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "NnCiZyFCBDmd"
      },
      "outputs": [],
      "source": [
        "class ConvVAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvVAE,self).__init__()\n",
        "    #self.input_size = input_size\n",
        "    self.Encoder = ConvEncoder(Bottleneck, layer_list=[2, 3, 5, 5])\n",
        "    self.reparam = Reparam()\n",
        "    self.Decoder = ConvDecoder()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.Encoder(x)\n",
        "    mu, log_var, z = self.reparam(x)\n",
        "    reconstruction = self.Decoder(z)\n",
        "\n",
        "    return reconstruction, mu, log_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UXTE_qTpCZja"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "# import model\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import matplotlib\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torchvision.utils import make_grid\n",
        "# from engine import train, validate\n",
        "# from utils import save_reconstructed_images, image_to_vid, save_loss_plot\n",
        "matplotlib.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxx1xRhvHUqr",
        "outputId": "b0d4d750-e82a-415a-d70c-5824c6a2d5bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/ValDatasetFull': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Folder path to be deleted\n",
        "folder_to_delete = '/content/ValDatasetFull'\n",
        "\n",
        "# Use the rm command to delete the folder and its contents\n",
        "!rm -r $folder_to_delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxqeLKOEGUMX",
        "outputId": "1b9ed73d-44e3-471e-aecf-2f69c6af9d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘ValDatasetFull’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ValDatasetFull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7RJpqxEBHdSk"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/ValDatasetFull/Depth17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NgvhxnREGaX7"
      },
      "outputs": [],
      "source": [
        "# Source folder path\n",
        "source_folder = '/content/TrainDatasetFull/depth17'\n",
        "\n",
        "# Destination folder path\n",
        "destination_folder = '/content/ValDatasetFull/Depth17'\n",
        "\n",
        "\n",
        "# Copy the entire contents of the source folder to the destination folder\n",
        "!cp -r $source_folder/* $destination_folder/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UDGtlwZMCLwc"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "dataroot = '/content/TrainDatasetFull' #Add your file path here\n",
        "\n",
        "val_dataroot = '/content/ValDatasetFull' #Add your file path here\n",
        "transforms = transforms.Compose([\n",
        "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.CenterCrop((640, 360)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "]) #Add Transforms\n",
        "\n",
        "dataset = dset.ImageFolder(root=dataroot, transform=transforms)\n",
        "\n",
        "val_dataset =  dset.ImageFolder(root=val_dataroot, transform=transforms)\n",
        "\n",
        "# Create the dataloader\n",
        "#TODO\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True)#Add dataloader\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False)#Add dataloader\n",
        "\n",
        "trainset = dataset\n",
        "testset = val_dataset\n",
        "trainloader = dataloader\n",
        "\n",
        "testloader = val_dataloader\n",
        "\n",
        "#Select device\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLtETxD6_jXG",
        "outputId": "4a02e28f-8046-4c6a-d22f-6ba01e239b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 640, 360])\n"
          ]
        }
      ],
      "source": [
        "for batch in dataset:\n",
        "  x,_ = batch\n",
        "  print(x.shape)\n",
        "  #print(y)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbdbZmpmGJQy",
        "outputId": "a3be070c-4121-4ddb-b158-2f679223b96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# initialize the model\n",
        "model = ConvVAE().to(device)\n",
        "# set the learning parameters\n",
        "lr = 0.0002\n",
        "epochs = 100\n",
        "#batch_size = 128\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "# criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
        "criterion = nn.MSELoss(reduction='mean')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# a list to save all the reconstructed images in PyTorch grid format\n",
        "grid_images = []\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTdgPdd6wyD4",
        "outputId": "9f9e0414-fbec-405b-a63a-62f366bd9972"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================================================================\n",
            "                                                       Kernel Shape  \\\n",
            "Layer                                                                 \n",
            "0_Encoder.Conv2d_conv1                                [3, 64, 7, 7]   \n",
            "1_Encoder.BatchNorm2d_batch_norm1                              [64]   \n",
            "2_Encoder.ReLU_relu                                               -   \n",
            "3_Encoder.MaxPool2d_max_pool                                      -   \n",
            "4_Encoder.layer1.0.Conv2d_conv1                      [64, 64, 1, 1]   \n",
            "5_Encoder.layer1.0.BatchNorm2d_batch_norm1                     [64]   \n",
            "6_Encoder.layer1.0.ReLU_relu                                      -   \n",
            "7_Encoder.layer1.0.Conv2d_conv2                      [64, 64, 3, 3]   \n",
            "8_Encoder.layer1.0.BatchNorm2d_batch_norm2                     [64]   \n",
            "9_Encoder.layer1.0.ReLU_relu                                      -   \n",
            "10_Encoder.layer1.0.Conv2d_conv3                    [64, 128, 1, 1]   \n",
            "11_Encoder.layer1.0.BatchNorm2d_batch_norm3                   [128]   \n",
            "12_Encoder.layer1.0.StochasticDepth_SD                            -   \n",
            "13_Encoder.layer1.0.i_downsample.Conv2d_0           [64, 128, 1, 1]   \n",
            "14_Encoder.layer1.0.i_downsample.BatchNorm2d_1                [128]   \n",
            "15_Encoder.layer1.0.ReLU_relu                                     -   \n",
            "16_Encoder.layer1.1.Conv2d_conv1                    [128, 64, 1, 1]   \n",
            "17_Encoder.layer1.1.BatchNorm2d_batch_norm1                    [64]   \n",
            "18_Encoder.layer1.1.ReLU_relu                                     -   \n",
            "19_Encoder.layer1.1.Conv2d_conv2                     [64, 64, 3, 3]   \n",
            "20_Encoder.layer1.1.BatchNorm2d_batch_norm2                    [64]   \n",
            "21_Encoder.layer1.1.ReLU_relu                                     -   \n",
            "22_Encoder.layer1.1.Conv2d_conv3                    [64, 128, 1, 1]   \n",
            "23_Encoder.layer1.1.BatchNorm2d_batch_norm3                   [128]   \n",
            "24_Encoder.layer1.1.StochasticDepth_SD                            -   \n",
            "25_Encoder.layer1.1.ReLU_relu                                     -   \n",
            "26_Encoder.layer2.0.Conv2d_conv1                   [128, 128, 1, 1]   \n",
            "27_Encoder.layer2.0.BatchNorm2d_batch_norm1                   [128]   \n",
            "28_Encoder.layer2.0.ReLU_relu                                     -   \n",
            "29_Encoder.layer2.0.Conv2d_conv2                   [128, 128, 3, 3]   \n",
            "30_Encoder.layer2.0.BatchNorm2d_batch_norm2                   [128]   \n",
            "31_Encoder.layer2.0.ReLU_relu                                     -   \n",
            "32_Encoder.layer2.0.Conv2d_conv3                   [128, 256, 1, 1]   \n",
            "33_Encoder.layer2.0.BatchNorm2d_batch_norm3                   [256]   \n",
            "34_Encoder.layer2.0.StochasticDepth_SD                            -   \n",
            "35_Encoder.layer2.0.i_downsample.Conv2d_0          [128, 256, 1, 1]   \n",
            "36_Encoder.layer2.0.i_downsample.BatchNorm2d_1                [256]   \n",
            "37_Encoder.layer2.0.ReLU_relu                                     -   \n",
            "38_Encoder.layer2.1.Conv2d_conv1                   [256, 128, 1, 1]   \n",
            "39_Encoder.layer2.1.BatchNorm2d_batch_norm1                   [128]   \n",
            "40_Encoder.layer2.1.ReLU_relu                                     -   \n",
            "41_Encoder.layer2.1.Conv2d_conv2                   [128, 128, 3, 3]   \n",
            "42_Encoder.layer2.1.BatchNorm2d_batch_norm2                   [128]   \n",
            "43_Encoder.layer2.1.ReLU_relu                                     -   \n",
            "44_Encoder.layer2.1.Conv2d_conv3                   [128, 256, 1, 1]   \n",
            "45_Encoder.layer2.1.BatchNorm2d_batch_norm3                   [256]   \n",
            "46_Encoder.layer2.1.StochasticDepth_SD                            -   \n",
            "47_Encoder.layer2.1.ReLU_relu                                     -   \n",
            "48_Encoder.layer2.2.Conv2d_conv1                   [256, 128, 1, 1]   \n",
            "49_Encoder.layer2.2.BatchNorm2d_batch_norm1                   [128]   \n",
            "50_Encoder.layer2.2.ReLU_relu                                     -   \n",
            "51_Encoder.layer2.2.Conv2d_conv2                   [128, 128, 3, 3]   \n",
            "52_Encoder.layer2.2.BatchNorm2d_batch_norm2                   [128]   \n",
            "53_Encoder.layer2.2.ReLU_relu                                     -   \n",
            "54_Encoder.layer2.2.Conv2d_conv3                   [128, 256, 1, 1]   \n",
            "55_Encoder.layer2.2.BatchNorm2d_batch_norm3                   [256]   \n",
            "56_Encoder.layer2.2.StochasticDepth_SD                            -   \n",
            "57_Encoder.layer2.2.ReLU_relu                                     -   \n",
            "58_Encoder.layer3.0.Conv2d_conv1                   [256, 256, 1, 1]   \n",
            "59_Encoder.layer3.0.BatchNorm2d_batch_norm1                   [256]   \n",
            "60_Encoder.layer3.0.ReLU_relu                                     -   \n",
            "61_Encoder.layer3.0.Conv2d_conv2                   [256, 256, 3, 3]   \n",
            "62_Encoder.layer3.0.BatchNorm2d_batch_norm2                   [256]   \n",
            "63_Encoder.layer3.0.ReLU_relu                                     -   \n",
            "64_Encoder.layer3.0.Conv2d_conv3                   [256, 512, 1, 1]   \n",
            "65_Encoder.layer3.0.BatchNorm2d_batch_norm3                   [512]   \n",
            "66_Encoder.layer3.0.StochasticDepth_SD                            -   \n",
            "67_Encoder.layer3.0.i_downsample.Conv2d_0          [256, 512, 1, 1]   \n",
            "68_Encoder.layer3.0.i_downsample.BatchNorm2d_1                [512]   \n",
            "69_Encoder.layer3.0.ReLU_relu                                     -   \n",
            "70_Encoder.layer3.1.Conv2d_conv1                   [512, 256, 1, 1]   \n",
            "71_Encoder.layer3.1.BatchNorm2d_batch_norm1                   [256]   \n",
            "72_Encoder.layer3.1.ReLU_relu                                     -   \n",
            "73_Encoder.layer3.1.Conv2d_conv2                   [256, 256, 3, 3]   \n",
            "74_Encoder.layer3.1.BatchNorm2d_batch_norm2                   [256]   \n",
            "75_Encoder.layer3.1.ReLU_relu                                     -   \n",
            "76_Encoder.layer3.1.Conv2d_conv3                   [256, 512, 1, 1]   \n",
            "77_Encoder.layer3.1.BatchNorm2d_batch_norm3                   [512]   \n",
            "78_Encoder.layer3.1.StochasticDepth_SD                            -   \n",
            "79_Encoder.layer3.1.ReLU_relu                                     -   \n",
            "80_Encoder.layer3.2.Conv2d_conv1                   [512, 256, 1, 1]   \n",
            "81_Encoder.layer3.2.BatchNorm2d_batch_norm1                   [256]   \n",
            "82_Encoder.layer3.2.ReLU_relu                                     -   \n",
            "83_Encoder.layer3.2.Conv2d_conv2                   [256, 256, 3, 3]   \n",
            "84_Encoder.layer3.2.BatchNorm2d_batch_norm2                   [256]   \n",
            "85_Encoder.layer3.2.ReLU_relu                                     -   \n",
            "86_Encoder.layer3.2.Conv2d_conv3                   [256, 512, 1, 1]   \n",
            "87_Encoder.layer3.2.BatchNorm2d_batch_norm3                   [512]   \n",
            "88_Encoder.layer3.2.StochasticDepth_SD                            -   \n",
            "89_Encoder.layer3.2.ReLU_relu                                     -   \n",
            "90_Encoder.layer3.3.Conv2d_conv1                   [512, 256, 1, 1]   \n",
            "91_Encoder.layer3.3.BatchNorm2d_batch_norm1                   [256]   \n",
            "92_Encoder.layer3.3.ReLU_relu                                     -   \n",
            "93_Encoder.layer3.3.Conv2d_conv2                   [256, 256, 3, 3]   \n",
            "94_Encoder.layer3.3.BatchNorm2d_batch_norm2                   [256]   \n",
            "95_Encoder.layer3.3.ReLU_relu                                     -   \n",
            "96_Encoder.layer3.3.Conv2d_conv3                   [256, 512, 1, 1]   \n",
            "97_Encoder.layer3.3.BatchNorm2d_batch_norm3                   [512]   \n",
            "98_Encoder.layer3.3.StochasticDepth_SD                            -   \n",
            "99_Encoder.layer3.3.ReLU_relu                                     -   \n",
            "100_Encoder.layer3.4.Conv2d_conv1                  [512, 256, 1, 1]   \n",
            "101_Encoder.layer3.4.BatchNorm2d_batch_norm1                  [256]   \n",
            "102_Encoder.layer3.4.ReLU_relu                                    -   \n",
            "103_Encoder.layer3.4.Conv2d_conv2                  [256, 256, 3, 3]   \n",
            "104_Encoder.layer3.4.BatchNorm2d_batch_norm2                  [256]   \n",
            "105_Encoder.layer3.4.ReLU_relu                                    -   \n",
            "106_Encoder.layer3.4.Conv2d_conv3                  [256, 512, 1, 1]   \n",
            "107_Encoder.layer3.4.BatchNorm2d_batch_norm3                  [512]   \n",
            "108_Encoder.layer3.4.StochasticDepth_SD                           -   \n",
            "109_Encoder.layer3.4.ReLU_relu                                    -   \n",
            "110_Encoder.layer4.0.Conv2d_conv1                  [512, 256, 1, 1]   \n",
            "111_Encoder.layer4.0.BatchNorm2d_batch_norm1                  [256]   \n",
            "112_Encoder.layer4.0.ReLU_relu                                    -   \n",
            "113_Encoder.layer4.0.Conv2d_conv2                  [256, 256, 3, 3]   \n",
            "114_Encoder.layer4.0.BatchNorm2d_batch_norm2                  [256]   \n",
            "115_Encoder.layer4.0.ReLU_relu                                    -   \n",
            "116_Encoder.layer4.0.Conv2d_conv3                  [256, 512, 1, 1]   \n",
            "117_Encoder.layer4.0.BatchNorm2d_batch_norm3                  [512]   \n",
            "118_Encoder.layer4.0.StochasticDepth_SD                           -   \n",
            "119_Encoder.layer4.0.i_downsample.Conv2d_0         [512, 512, 1, 1]   \n",
            "120_Encoder.layer4.0.i_downsample.BatchNorm2d_1               [512]   \n",
            "121_Encoder.layer4.0.ReLU_relu                                    -   \n",
            "122_Encoder.layer4.1.Conv2d_conv1                  [512, 256, 1, 1]   \n",
            "123_Encoder.layer4.1.BatchNorm2d_batch_norm1                  [256]   \n",
            "124_Encoder.layer4.1.ReLU_relu                                    -   \n",
            "125_Encoder.layer4.1.Conv2d_conv2                  [256, 256, 3, 3]   \n",
            "126_Encoder.layer4.1.BatchNorm2d_batch_norm2                  [256]   \n",
            "127_Encoder.layer4.1.ReLU_relu                                    -   \n",
            "128_Encoder.layer4.1.Conv2d_conv3                  [256, 512, 1, 1]   \n",
            "129_Encoder.layer4.1.BatchNorm2d_batch_norm3                  [512]   \n",
            "130_Encoder.layer4.1.StochasticDepth_SD                           -   \n",
            "131_Encoder.layer4.1.ReLU_relu                                    -   \n",
            "132_Encoder.layer4.2.Conv2d_conv1                  [512, 256, 1, 1]   \n",
            "133_Encoder.layer4.2.BatchNorm2d_batch_norm1                  [256]   \n",
            "134_Encoder.layer4.2.ReLU_relu                                    -   \n",
            "135_Encoder.layer4.2.Conv2d_conv2                  [256, 256, 3, 3]   \n",
            "136_Encoder.layer4.2.BatchNorm2d_batch_norm2                  [256]   \n",
            "137_Encoder.layer4.2.ReLU_relu                                    -   \n",
            "138_Encoder.layer4.2.Conv2d_conv3                  [256, 512, 1, 1]   \n",
            "139_Encoder.layer4.2.BatchNorm2d_batch_norm3                  [512]   \n",
            "140_Encoder.layer4.2.StochasticDepth_SD                           -   \n",
            "141_Encoder.layer4.2.ReLU_relu                                    -   \n",
            "142_Encoder.layer4.3.Conv2d_conv1                  [512, 256, 1, 1]   \n",
            "143_Encoder.layer4.3.BatchNorm2d_batch_norm1                  [256]   \n",
            "144_Encoder.layer4.3.ReLU_relu                                    -   \n",
            "145_Encoder.layer4.3.Conv2d_conv2                  [256, 256, 3, 3]   \n",
            "146_Encoder.layer4.3.BatchNorm2d_batch_norm2                  [256]   \n",
            "147_Encoder.layer4.3.ReLU_relu                                    -   \n",
            "148_Encoder.layer4.3.Conv2d_conv3                  [256, 512, 1, 1]   \n",
            "149_Encoder.layer4.3.BatchNorm2d_batch_norm3                  [512]   \n",
            "150_Encoder.layer4.3.StochasticDepth_SD                           -   \n",
            "151_Encoder.layer4.3.ReLU_relu                                    -   \n",
            "152_Encoder.layer4.4.Conv2d_conv1                  [512, 256, 1, 1]   \n",
            "153_Encoder.layer4.4.BatchNorm2d_batch_norm1                  [256]   \n",
            "154_Encoder.layer4.4.ReLU_relu                                    -   \n",
            "155_Encoder.layer4.4.Conv2d_conv2                  [256, 256, 3, 3]   \n",
            "156_Encoder.layer4.4.BatchNorm2d_batch_norm2                  [256]   \n",
            "157_Encoder.layer4.4.ReLU_relu                                    -   \n",
            "158_Encoder.layer4.4.Conv2d_conv3                  [256, 512, 1, 1]   \n",
            "159_Encoder.layer4.4.BatchNorm2d_batch_norm3                  [512]   \n",
            "160_Encoder.layer4.4.StochasticDepth_SD                           -   \n",
            "161_Encoder.layer4.4.ReLU_relu                                    -   \n",
            "162_reparam.Linear_fc1                                   [512, 512]   \n",
            "163_reparam.Linear_fc_mu                                 [512, 512]   \n",
            "164_reparam.Linear_fc_log_var                            [512, 512]   \n",
            "165_reparam.Linear_fc2                                   [512, 512]   \n",
            "166_Decoder.ConvTranspose2d_dec1                  [256, 512, 16, 9]   \n",
            "167_Decoder.ConvTranspose2d_dec2                 [128, 256, 19, 12]   \n",
            "168_Decoder.ConvTranspose2d_dec3                  [64, 128, 19, 12]   \n",
            "169_Decoder.ConvTranspose2d_dec4                     [32, 64, 8, 8]   \n",
            "170_Decoder.ConvTranspose2d_dec5                     [16, 32, 8, 8]   \n",
            "171_Decoder.ConvTranspose2d_dec6                      [8, 16, 8, 8]   \n",
            "172_Decoder.ConvTranspose2d_dec7                       [3, 8, 3, 3]   \n",
            "\n",
            "                                                       Output Shape  \\\n",
            "Layer                                                                 \n",
            "0_Encoder.Conv2d_conv1                           [64, 64, 320, 180]   \n",
            "1_Encoder.BatchNorm2d_batch_norm1                [64, 64, 320, 180]   \n",
            "2_Encoder.ReLU_relu                              [64, 64, 320, 180]   \n",
            "3_Encoder.MaxPool2d_max_pool                      [64, 64, 160, 90]   \n",
            "4_Encoder.layer1.0.Conv2d_conv1                   [64, 64, 160, 90]   \n",
            "5_Encoder.layer1.0.BatchNorm2d_batch_norm1        [64, 64, 160, 90]   \n",
            "6_Encoder.layer1.0.ReLU_relu                      [64, 64, 160, 90]   \n",
            "7_Encoder.layer1.0.Conv2d_conv2                   [64, 64, 160, 90]   \n",
            "8_Encoder.layer1.0.BatchNorm2d_batch_norm2        [64, 64, 160, 90]   \n",
            "9_Encoder.layer1.0.ReLU_relu                      [64, 64, 160, 90]   \n",
            "10_Encoder.layer1.0.Conv2d_conv3                 [64, 128, 160, 90]   \n",
            "11_Encoder.layer1.0.BatchNorm2d_batch_norm3      [64, 128, 160, 90]   \n",
            "12_Encoder.layer1.0.StochasticDepth_SD           [64, 128, 160, 90]   \n",
            "13_Encoder.layer1.0.i_downsample.Conv2d_0        [64, 128, 160, 90]   \n",
            "14_Encoder.layer1.0.i_downsample.BatchNorm2d_1   [64, 128, 160, 90]   \n",
            "15_Encoder.layer1.0.ReLU_relu                    [64, 128, 160, 90]   \n",
            "16_Encoder.layer1.1.Conv2d_conv1                  [64, 64, 160, 90]   \n",
            "17_Encoder.layer1.1.BatchNorm2d_batch_norm1       [64, 64, 160, 90]   \n",
            "18_Encoder.layer1.1.ReLU_relu                     [64, 64, 160, 90]   \n",
            "19_Encoder.layer1.1.Conv2d_conv2                  [64, 64, 160, 90]   \n",
            "20_Encoder.layer1.1.BatchNorm2d_batch_norm2       [64, 64, 160, 90]   \n",
            "21_Encoder.layer1.1.ReLU_relu                     [64, 64, 160, 90]   \n",
            "22_Encoder.layer1.1.Conv2d_conv3                 [64, 128, 160, 90]   \n",
            "23_Encoder.layer1.1.BatchNorm2d_batch_norm3      [64, 128, 160, 90]   \n",
            "24_Encoder.layer1.1.StochasticDepth_SD           [64, 128, 160, 90]   \n",
            "25_Encoder.layer1.1.ReLU_relu                    [64, 128, 160, 90]   \n",
            "26_Encoder.layer2.0.Conv2d_conv1                 [64, 128, 160, 90]   \n",
            "27_Encoder.layer2.0.BatchNorm2d_batch_norm1      [64, 128, 160, 90]   \n",
            "28_Encoder.layer2.0.ReLU_relu                    [64, 128, 160, 90]   \n",
            "29_Encoder.layer2.0.Conv2d_conv2                  [64, 128, 80, 45]   \n",
            "30_Encoder.layer2.0.BatchNorm2d_batch_norm2       [64, 128, 80, 45]   \n",
            "31_Encoder.layer2.0.ReLU_relu                     [64, 128, 80, 45]   \n",
            "32_Encoder.layer2.0.Conv2d_conv3                  [64, 256, 80, 45]   \n",
            "33_Encoder.layer2.0.BatchNorm2d_batch_norm3       [64, 256, 80, 45]   \n",
            "34_Encoder.layer2.0.StochasticDepth_SD            [64, 256, 80, 45]   \n",
            "35_Encoder.layer2.0.i_downsample.Conv2d_0         [64, 256, 80, 45]   \n",
            "36_Encoder.layer2.0.i_downsample.BatchNorm2d_1    [64, 256, 80, 45]   \n",
            "37_Encoder.layer2.0.ReLU_relu                     [64, 256, 80, 45]   \n",
            "38_Encoder.layer2.1.Conv2d_conv1                  [64, 128, 80, 45]   \n",
            "39_Encoder.layer2.1.BatchNorm2d_batch_norm1       [64, 128, 80, 45]   \n",
            "40_Encoder.layer2.1.ReLU_relu                     [64, 128, 80, 45]   \n",
            "41_Encoder.layer2.1.Conv2d_conv2                  [64, 128, 80, 45]   \n",
            "42_Encoder.layer2.1.BatchNorm2d_batch_norm2       [64, 128, 80, 45]   \n",
            "43_Encoder.layer2.1.ReLU_relu                     [64, 128, 80, 45]   \n",
            "44_Encoder.layer2.1.Conv2d_conv3                  [64, 256, 80, 45]   \n",
            "45_Encoder.layer2.1.BatchNorm2d_batch_norm3       [64, 256, 80, 45]   \n",
            "46_Encoder.layer2.1.StochasticDepth_SD            [64, 256, 80, 45]   \n",
            "47_Encoder.layer2.1.ReLU_relu                     [64, 256, 80, 45]   \n",
            "48_Encoder.layer2.2.Conv2d_conv1                  [64, 128, 80, 45]   \n",
            "49_Encoder.layer2.2.BatchNorm2d_batch_norm1       [64, 128, 80, 45]   \n",
            "50_Encoder.layer2.2.ReLU_relu                     [64, 128, 80, 45]   \n",
            "51_Encoder.layer2.2.Conv2d_conv2                  [64, 128, 80, 45]   \n",
            "52_Encoder.layer2.2.BatchNorm2d_batch_norm2       [64, 128, 80, 45]   \n",
            "53_Encoder.layer2.2.ReLU_relu                     [64, 128, 80, 45]   \n",
            "54_Encoder.layer2.2.Conv2d_conv3                  [64, 256, 80, 45]   \n",
            "55_Encoder.layer2.2.BatchNorm2d_batch_norm3       [64, 256, 80, 45]   \n",
            "56_Encoder.layer2.2.StochasticDepth_SD            [64, 256, 80, 45]   \n",
            "57_Encoder.layer2.2.ReLU_relu                     [64, 256, 80, 45]   \n",
            "58_Encoder.layer3.0.Conv2d_conv1                  [64, 256, 80, 45]   \n",
            "59_Encoder.layer3.0.BatchNorm2d_batch_norm1       [64, 256, 80, 45]   \n",
            "60_Encoder.layer3.0.ReLU_relu                     [64, 256, 80, 45]   \n",
            "61_Encoder.layer3.0.Conv2d_conv2                  [64, 256, 40, 23]   \n",
            "62_Encoder.layer3.0.BatchNorm2d_batch_norm2       [64, 256, 40, 23]   \n",
            "63_Encoder.layer3.0.ReLU_relu                     [64, 256, 40, 23]   \n",
            "64_Encoder.layer3.0.Conv2d_conv3                  [64, 512, 40, 23]   \n",
            "65_Encoder.layer3.0.BatchNorm2d_batch_norm3       [64, 512, 40, 23]   \n",
            "66_Encoder.layer3.0.StochasticDepth_SD            [64, 512, 40, 23]   \n",
            "67_Encoder.layer3.0.i_downsample.Conv2d_0         [64, 512, 40, 23]   \n",
            "68_Encoder.layer3.0.i_downsample.BatchNorm2d_1    [64, 512, 40, 23]   \n",
            "69_Encoder.layer3.0.ReLU_relu                     [64, 512, 40, 23]   \n",
            "70_Encoder.layer3.1.Conv2d_conv1                  [64, 256, 40, 23]   \n",
            "71_Encoder.layer3.1.BatchNorm2d_batch_norm1       [64, 256, 40, 23]   \n",
            "72_Encoder.layer3.1.ReLU_relu                     [64, 256, 40, 23]   \n",
            "73_Encoder.layer3.1.Conv2d_conv2                  [64, 256, 40, 23]   \n",
            "74_Encoder.layer3.1.BatchNorm2d_batch_norm2       [64, 256, 40, 23]   \n",
            "75_Encoder.layer3.1.ReLU_relu                     [64, 256, 40, 23]   \n",
            "76_Encoder.layer3.1.Conv2d_conv3                  [64, 512, 40, 23]   \n",
            "77_Encoder.layer3.1.BatchNorm2d_batch_norm3       [64, 512, 40, 23]   \n",
            "78_Encoder.layer3.1.StochasticDepth_SD            [64, 512, 40, 23]   \n",
            "79_Encoder.layer3.1.ReLU_relu                     [64, 512, 40, 23]   \n",
            "80_Encoder.layer3.2.Conv2d_conv1                  [64, 256, 40, 23]   \n",
            "81_Encoder.layer3.2.BatchNorm2d_batch_norm1       [64, 256, 40, 23]   \n",
            "82_Encoder.layer3.2.ReLU_relu                     [64, 256, 40, 23]   \n",
            "83_Encoder.layer3.2.Conv2d_conv2                  [64, 256, 40, 23]   \n",
            "84_Encoder.layer3.2.BatchNorm2d_batch_norm2       [64, 256, 40, 23]   \n",
            "85_Encoder.layer3.2.ReLU_relu                     [64, 256, 40, 23]   \n",
            "86_Encoder.layer3.2.Conv2d_conv3                  [64, 512, 40, 23]   \n",
            "87_Encoder.layer3.2.BatchNorm2d_batch_norm3       [64, 512, 40, 23]   \n",
            "88_Encoder.layer3.2.StochasticDepth_SD            [64, 512, 40, 23]   \n",
            "89_Encoder.layer3.2.ReLU_relu                     [64, 512, 40, 23]   \n",
            "90_Encoder.layer3.3.Conv2d_conv1                  [64, 256, 40, 23]   \n",
            "91_Encoder.layer3.3.BatchNorm2d_batch_norm1       [64, 256, 40, 23]   \n",
            "92_Encoder.layer3.3.ReLU_relu                     [64, 256, 40, 23]   \n",
            "93_Encoder.layer3.3.Conv2d_conv2                  [64, 256, 40, 23]   \n",
            "94_Encoder.layer3.3.BatchNorm2d_batch_norm2       [64, 256, 40, 23]   \n",
            "95_Encoder.layer3.3.ReLU_relu                     [64, 256, 40, 23]   \n",
            "96_Encoder.layer3.3.Conv2d_conv3                  [64, 512, 40, 23]   \n",
            "97_Encoder.layer3.3.BatchNorm2d_batch_norm3       [64, 512, 40, 23]   \n",
            "98_Encoder.layer3.3.StochasticDepth_SD            [64, 512, 40, 23]   \n",
            "99_Encoder.layer3.3.ReLU_relu                     [64, 512, 40, 23]   \n",
            "100_Encoder.layer3.4.Conv2d_conv1                 [64, 256, 40, 23]   \n",
            "101_Encoder.layer3.4.BatchNorm2d_batch_norm1      [64, 256, 40, 23]   \n",
            "102_Encoder.layer3.4.ReLU_relu                    [64, 256, 40, 23]   \n",
            "103_Encoder.layer3.4.Conv2d_conv2                 [64, 256, 40, 23]   \n",
            "104_Encoder.layer3.4.BatchNorm2d_batch_norm2      [64, 256, 40, 23]   \n",
            "105_Encoder.layer3.4.ReLU_relu                    [64, 256, 40, 23]   \n",
            "106_Encoder.layer3.4.Conv2d_conv3                 [64, 512, 40, 23]   \n",
            "107_Encoder.layer3.4.BatchNorm2d_batch_norm3      [64, 512, 40, 23]   \n",
            "108_Encoder.layer3.4.StochasticDepth_SD           [64, 512, 40, 23]   \n",
            "109_Encoder.layer3.4.ReLU_relu                    [64, 512, 40, 23]   \n",
            "110_Encoder.layer4.0.Conv2d_conv1                 [64, 256, 40, 23]   \n",
            "111_Encoder.layer4.0.BatchNorm2d_batch_norm1      [64, 256, 40, 23]   \n",
            "112_Encoder.layer4.0.ReLU_relu                    [64, 256, 40, 23]   \n",
            "113_Encoder.layer4.0.Conv2d_conv2                 [64, 256, 20, 12]   \n",
            "114_Encoder.layer4.0.BatchNorm2d_batch_norm2      [64, 256, 20, 12]   \n",
            "115_Encoder.layer4.0.ReLU_relu                    [64, 256, 20, 12]   \n",
            "116_Encoder.layer4.0.Conv2d_conv3                 [64, 512, 20, 12]   \n",
            "117_Encoder.layer4.0.BatchNorm2d_batch_norm3      [64, 512, 20, 12]   \n",
            "118_Encoder.layer4.0.StochasticDepth_SD           [64, 512, 20, 12]   \n",
            "119_Encoder.layer4.0.i_downsample.Conv2d_0        [64, 512, 20, 12]   \n",
            "120_Encoder.layer4.0.i_downsample.BatchNorm2d_1   [64, 512, 20, 12]   \n",
            "121_Encoder.layer4.0.ReLU_relu                    [64, 512, 20, 12]   \n",
            "122_Encoder.layer4.1.Conv2d_conv1                 [64, 256, 20, 12]   \n",
            "123_Encoder.layer4.1.BatchNorm2d_batch_norm1      [64, 256, 20, 12]   \n",
            "124_Encoder.layer4.1.ReLU_relu                    [64, 256, 20, 12]   \n",
            "125_Encoder.layer4.1.Conv2d_conv2                 [64, 256, 20, 12]   \n",
            "126_Encoder.layer4.1.BatchNorm2d_batch_norm2      [64, 256, 20, 12]   \n",
            "127_Encoder.layer4.1.ReLU_relu                    [64, 256, 20, 12]   \n",
            "128_Encoder.layer4.1.Conv2d_conv3                 [64, 512, 20, 12]   \n",
            "129_Encoder.layer4.1.BatchNorm2d_batch_norm3      [64, 512, 20, 12]   \n",
            "130_Encoder.layer4.1.StochasticDepth_SD           [64, 512, 20, 12]   \n",
            "131_Encoder.layer4.1.ReLU_relu                    [64, 512, 20, 12]   \n",
            "132_Encoder.layer4.2.Conv2d_conv1                 [64, 256, 20, 12]   \n",
            "133_Encoder.layer4.2.BatchNorm2d_batch_norm1      [64, 256, 20, 12]   \n",
            "134_Encoder.layer4.2.ReLU_relu                    [64, 256, 20, 12]   \n",
            "135_Encoder.layer4.2.Conv2d_conv2                 [64, 256, 20, 12]   \n",
            "136_Encoder.layer4.2.BatchNorm2d_batch_norm2      [64, 256, 20, 12]   \n",
            "137_Encoder.layer4.2.ReLU_relu                    [64, 256, 20, 12]   \n",
            "138_Encoder.layer4.2.Conv2d_conv3                 [64, 512, 20, 12]   \n",
            "139_Encoder.layer4.2.BatchNorm2d_batch_norm3      [64, 512, 20, 12]   \n",
            "140_Encoder.layer4.2.StochasticDepth_SD           [64, 512, 20, 12]   \n",
            "141_Encoder.layer4.2.ReLU_relu                    [64, 512, 20, 12]   \n",
            "142_Encoder.layer4.3.Conv2d_conv1                 [64, 256, 20, 12]   \n",
            "143_Encoder.layer4.3.BatchNorm2d_batch_norm1      [64, 256, 20, 12]   \n",
            "144_Encoder.layer4.3.ReLU_relu                    [64, 256, 20, 12]   \n",
            "145_Encoder.layer4.3.Conv2d_conv2                 [64, 256, 20, 12]   \n",
            "146_Encoder.layer4.3.BatchNorm2d_batch_norm2      [64, 256, 20, 12]   \n",
            "147_Encoder.layer4.3.ReLU_relu                    [64, 256, 20, 12]   \n",
            "148_Encoder.layer4.3.Conv2d_conv3                 [64, 512, 20, 12]   \n",
            "149_Encoder.layer4.3.BatchNorm2d_batch_norm3      [64, 512, 20, 12]   \n",
            "150_Encoder.layer4.3.StochasticDepth_SD           [64, 512, 20, 12]   \n",
            "151_Encoder.layer4.3.ReLU_relu                    [64, 512, 20, 12]   \n",
            "152_Encoder.layer4.4.Conv2d_conv1                 [64, 256, 20, 12]   \n",
            "153_Encoder.layer4.4.BatchNorm2d_batch_norm1      [64, 256, 20, 12]   \n",
            "154_Encoder.layer4.4.ReLU_relu                    [64, 256, 20, 12]   \n",
            "155_Encoder.layer4.4.Conv2d_conv2                 [64, 256, 20, 12]   \n",
            "156_Encoder.layer4.4.BatchNorm2d_batch_norm2      [64, 256, 20, 12]   \n",
            "157_Encoder.layer4.4.ReLU_relu                    [64, 256, 20, 12]   \n",
            "158_Encoder.layer4.4.Conv2d_conv3                 [64, 512, 20, 12]   \n",
            "159_Encoder.layer4.4.BatchNorm2d_batch_norm3      [64, 512, 20, 12]   \n",
            "160_Encoder.layer4.4.StochasticDepth_SD           [64, 512, 20, 12]   \n",
            "161_Encoder.layer4.4.ReLU_relu                    [64, 512, 20, 12]   \n",
            "162_reparam.Linear_fc1                                    [64, 512]   \n",
            "163_reparam.Linear_fc_mu                                  [64, 512]   \n",
            "164_reparam.Linear_fc_log_var                             [64, 512]   \n",
            "165_reparam.Linear_fc2                                    [64, 512]   \n",
            "166_Decoder.ConvTranspose2d_dec1                   [64, 256, 16, 9]   \n",
            "167_Decoder.ConvTranspose2d_dec2                  [64, 128, 64, 36]   \n",
            "168_Decoder.ConvTranspose2d_dec3                   [64, 64, 80, 45]   \n",
            "169_Decoder.ConvTranspose2d_dec4                  [64, 32, 160, 90]   \n",
            "170_Decoder.ConvTranspose2d_dec5                 [64, 16, 320, 180]   \n",
            "171_Decoder.ConvTranspose2d_dec6                  [64, 8, 640, 360]   \n",
            "172_Decoder.ConvTranspose2d_dec7                  [64, 3, 640, 360]   \n",
            "\n",
            "                                                     Params      Mult-Adds  \n",
            "Layer                                                                       \n",
            "0_Encoder.Conv2d_conv1                               9.408k      541.9008M  \n",
            "1_Encoder.BatchNorm2d_batch_norm1                     128.0           64.0  \n",
            "2_Encoder.ReLU_relu                                       -              -  \n",
            "3_Encoder.MaxPool2d_max_pool                              -              -  \n",
            "4_Encoder.layer1.0.Conv2d_conv1                       4.16k       58.9824M  \n",
            "5_Encoder.layer1.0.BatchNorm2d_batch_norm1            128.0           64.0  \n",
            "6_Encoder.layer1.0.ReLU_relu                              -              -  \n",
            "7_Encoder.layer1.0.Conv2d_conv2                     36.928k      530.8416M  \n",
            "8_Encoder.layer1.0.BatchNorm2d_batch_norm2            128.0           64.0  \n",
            "9_Encoder.layer1.0.ReLU_relu                              -              -  \n",
            "10_Encoder.layer1.0.Conv2d_conv3                      8.32k      117.9648M  \n",
            "11_Encoder.layer1.0.BatchNorm2d_batch_norm3           256.0          128.0  \n",
            "12_Encoder.layer1.0.StochasticDepth_SD                    -              -  \n",
            "13_Encoder.layer1.0.i_downsample.Conv2d_0             8.32k      117.9648M  \n",
            "14_Encoder.layer1.0.i_downsample.BatchNorm2d_1        256.0          128.0  \n",
            "15_Encoder.layer1.0.ReLU_relu                             -              -  \n",
            "16_Encoder.layer1.1.Conv2d_conv1                     8.256k      117.9648M  \n",
            "17_Encoder.layer1.1.BatchNorm2d_batch_norm1           128.0           64.0  \n",
            "18_Encoder.layer1.1.ReLU_relu                             -              -  \n",
            "19_Encoder.layer1.1.Conv2d_conv2                    36.928k      530.8416M  \n",
            "20_Encoder.layer1.1.BatchNorm2d_batch_norm2           128.0           64.0  \n",
            "21_Encoder.layer1.1.ReLU_relu                             -              -  \n",
            "22_Encoder.layer1.1.Conv2d_conv3                      8.32k      117.9648M  \n",
            "23_Encoder.layer1.1.BatchNorm2d_batch_norm3           256.0          128.0  \n",
            "24_Encoder.layer1.1.StochasticDepth_SD                    -              -  \n",
            "25_Encoder.layer1.1.ReLU_relu                             -              -  \n",
            "26_Encoder.layer2.0.Conv2d_conv1                    16.512k      235.9296M  \n",
            "27_Encoder.layer2.0.BatchNorm2d_batch_norm1           256.0          128.0  \n",
            "28_Encoder.layer2.0.ReLU_relu                             -              -  \n",
            "29_Encoder.layer2.0.Conv2d_conv2                   147.584k      530.8416M  \n",
            "30_Encoder.layer2.0.BatchNorm2d_batch_norm2           256.0          128.0  \n",
            "31_Encoder.layer2.0.ReLU_relu                             -              -  \n",
            "32_Encoder.layer2.0.Conv2d_conv3                    33.024k      117.9648M  \n",
            "33_Encoder.layer2.0.BatchNorm2d_batch_norm3           512.0          256.0  \n",
            "34_Encoder.layer2.0.StochasticDepth_SD                    -              -  \n",
            "35_Encoder.layer2.0.i_downsample.Conv2d_0           33.024k      117.9648M  \n",
            "36_Encoder.layer2.0.i_downsample.BatchNorm2d_1        512.0          256.0  \n",
            "37_Encoder.layer2.0.ReLU_relu                             -              -  \n",
            "38_Encoder.layer2.1.Conv2d_conv1                    32.896k      117.9648M  \n",
            "39_Encoder.layer2.1.BatchNorm2d_batch_norm1           256.0          128.0  \n",
            "40_Encoder.layer2.1.ReLU_relu                             -              -  \n",
            "41_Encoder.layer2.1.Conv2d_conv2                   147.584k      530.8416M  \n",
            "42_Encoder.layer2.1.BatchNorm2d_batch_norm2           256.0          128.0  \n",
            "43_Encoder.layer2.1.ReLU_relu                             -              -  \n",
            "44_Encoder.layer2.1.Conv2d_conv3                    33.024k      117.9648M  \n",
            "45_Encoder.layer2.1.BatchNorm2d_batch_norm3           512.0          256.0  \n",
            "46_Encoder.layer2.1.StochasticDepth_SD                    -              -  \n",
            "47_Encoder.layer2.1.ReLU_relu                             -              -  \n",
            "48_Encoder.layer2.2.Conv2d_conv1                    32.896k      117.9648M  \n",
            "49_Encoder.layer2.2.BatchNorm2d_batch_norm1           256.0          128.0  \n",
            "50_Encoder.layer2.2.ReLU_relu                             -              -  \n",
            "51_Encoder.layer2.2.Conv2d_conv2                   147.584k      530.8416M  \n",
            "52_Encoder.layer2.2.BatchNorm2d_batch_norm2           256.0          128.0  \n",
            "53_Encoder.layer2.2.ReLU_relu                             -              -  \n",
            "54_Encoder.layer2.2.Conv2d_conv3                    33.024k      117.9648M  \n",
            "55_Encoder.layer2.2.BatchNorm2d_batch_norm3           512.0          256.0  \n",
            "56_Encoder.layer2.2.StochasticDepth_SD                    -              -  \n",
            "57_Encoder.layer2.2.ReLU_relu                             -              -  \n",
            "58_Encoder.layer3.0.Conv2d_conv1                    65.792k      235.9296M  \n",
            "59_Encoder.layer3.0.BatchNorm2d_batch_norm1           512.0          256.0  \n",
            "60_Encoder.layer3.0.ReLU_relu                             -              -  \n",
            "61_Encoder.layer3.0.Conv2d_conv2                    590.08k     542.63808M  \n",
            "62_Encoder.layer3.0.BatchNorm2d_batch_norm2           512.0          256.0  \n",
            "63_Encoder.layer3.0.ReLU_relu                             -              -  \n",
            "64_Encoder.layer3.0.Conv2d_conv3                   131.584k     120.58624M  \n",
            "65_Encoder.layer3.0.BatchNorm2d_batch_norm3          1.024k          512.0  \n",
            "66_Encoder.layer3.0.StochasticDepth_SD                    -              -  \n",
            "67_Encoder.layer3.0.i_downsample.Conv2d_0          131.584k     120.58624M  \n",
            "68_Encoder.layer3.0.i_downsample.BatchNorm2d_1       1.024k          512.0  \n",
            "69_Encoder.layer3.0.ReLU_relu                             -              -  \n",
            "70_Encoder.layer3.1.Conv2d_conv1                   131.328k     120.58624M  \n",
            "71_Encoder.layer3.1.BatchNorm2d_batch_norm1           512.0          256.0  \n",
            "72_Encoder.layer3.1.ReLU_relu                             -              -  \n",
            "73_Encoder.layer3.1.Conv2d_conv2                    590.08k     542.63808M  \n",
            "74_Encoder.layer3.1.BatchNorm2d_batch_norm2           512.0          256.0  \n",
            "75_Encoder.layer3.1.ReLU_relu                             -              -  \n",
            "76_Encoder.layer3.1.Conv2d_conv3                   131.584k     120.58624M  \n",
            "77_Encoder.layer3.1.BatchNorm2d_batch_norm3          1.024k          512.0  \n",
            "78_Encoder.layer3.1.StochasticDepth_SD                    -              -  \n",
            "79_Encoder.layer3.1.ReLU_relu                             -              -  \n",
            "80_Encoder.layer3.2.Conv2d_conv1                   131.328k     120.58624M  \n",
            "81_Encoder.layer3.2.BatchNorm2d_batch_norm1           512.0          256.0  \n",
            "82_Encoder.layer3.2.ReLU_relu                             -              -  \n",
            "83_Encoder.layer3.2.Conv2d_conv2                    590.08k     542.63808M  \n",
            "84_Encoder.layer3.2.BatchNorm2d_batch_norm2           512.0          256.0  \n",
            "85_Encoder.layer3.2.ReLU_relu                             -              -  \n",
            "86_Encoder.layer3.2.Conv2d_conv3                   131.584k     120.58624M  \n",
            "87_Encoder.layer3.2.BatchNorm2d_batch_norm3          1.024k          512.0  \n",
            "88_Encoder.layer3.2.StochasticDepth_SD                    -              -  \n",
            "89_Encoder.layer3.2.ReLU_relu                             -              -  \n",
            "90_Encoder.layer3.3.Conv2d_conv1                   131.328k     120.58624M  \n",
            "91_Encoder.layer3.3.BatchNorm2d_batch_norm1           512.0          256.0  \n",
            "92_Encoder.layer3.3.ReLU_relu                             -              -  \n",
            "93_Encoder.layer3.3.Conv2d_conv2                    590.08k     542.63808M  \n",
            "94_Encoder.layer3.3.BatchNorm2d_batch_norm2           512.0          256.0  \n",
            "95_Encoder.layer3.3.ReLU_relu                             -              -  \n",
            "96_Encoder.layer3.3.Conv2d_conv3                   131.584k     120.58624M  \n",
            "97_Encoder.layer3.3.BatchNorm2d_batch_norm3          1.024k          512.0  \n",
            "98_Encoder.layer3.3.StochasticDepth_SD                    -              -  \n",
            "99_Encoder.layer3.3.ReLU_relu                             -              -  \n",
            "100_Encoder.layer3.4.Conv2d_conv1                  131.328k     120.58624M  \n",
            "101_Encoder.layer3.4.BatchNorm2d_batch_norm1          512.0          256.0  \n",
            "102_Encoder.layer3.4.ReLU_relu                            -              -  \n",
            "103_Encoder.layer3.4.Conv2d_conv2                   590.08k     542.63808M  \n",
            "104_Encoder.layer3.4.BatchNorm2d_batch_norm2          512.0          256.0  \n",
            "105_Encoder.layer3.4.ReLU_relu                            -              -  \n",
            "106_Encoder.layer3.4.Conv2d_conv3                  131.584k     120.58624M  \n",
            "107_Encoder.layer3.4.BatchNorm2d_batch_norm3         1.024k          512.0  \n",
            "108_Encoder.layer3.4.StochasticDepth_SD                   -              -  \n",
            "109_Encoder.layer3.4.ReLU_relu                            -              -  \n",
            "110_Encoder.layer4.0.Conv2d_conv1                  131.328k     120.58624M  \n",
            "111_Encoder.layer4.0.BatchNorm2d_batch_norm1          512.0          256.0  \n",
            "112_Encoder.layer4.0.ReLU_relu                            -              -  \n",
            "113_Encoder.layer4.0.Conv2d_conv2                   590.08k     141.55776M  \n",
            "114_Encoder.layer4.0.BatchNorm2d_batch_norm2          512.0          256.0  \n",
            "115_Encoder.layer4.0.ReLU_relu                            -              -  \n",
            "116_Encoder.layer4.0.Conv2d_conv3                  131.584k      31.45728M  \n",
            "117_Encoder.layer4.0.BatchNorm2d_batch_norm3         1.024k          512.0  \n",
            "118_Encoder.layer4.0.StochasticDepth_SD                   -              -  \n",
            "119_Encoder.layer4.0.i_downsample.Conv2d_0         262.656k      62.91456M  \n",
            "120_Encoder.layer4.0.i_downsample.BatchNorm2d_1      1.024k          512.0  \n",
            "121_Encoder.layer4.0.ReLU_relu                            -              -  \n",
            "122_Encoder.layer4.1.Conv2d_conv1                  131.328k      31.45728M  \n",
            "123_Encoder.layer4.1.BatchNorm2d_batch_norm1          512.0          256.0  \n",
            "124_Encoder.layer4.1.ReLU_relu                            -              -  \n",
            "125_Encoder.layer4.1.Conv2d_conv2                   590.08k     141.55776M  \n",
            "126_Encoder.layer4.1.BatchNorm2d_batch_norm2          512.0          256.0  \n",
            "127_Encoder.layer4.1.ReLU_relu                            -              -  \n",
            "128_Encoder.layer4.1.Conv2d_conv3                  131.584k      31.45728M  \n",
            "129_Encoder.layer4.1.BatchNorm2d_batch_norm3         1.024k          512.0  \n",
            "130_Encoder.layer4.1.StochasticDepth_SD                   -              -  \n",
            "131_Encoder.layer4.1.ReLU_relu                            -              -  \n",
            "132_Encoder.layer4.2.Conv2d_conv1                  131.328k      31.45728M  \n",
            "133_Encoder.layer4.2.BatchNorm2d_batch_norm1          512.0          256.0  \n",
            "134_Encoder.layer4.2.ReLU_relu                            -              -  \n",
            "135_Encoder.layer4.2.Conv2d_conv2                   590.08k     141.55776M  \n",
            "136_Encoder.layer4.2.BatchNorm2d_batch_norm2          512.0          256.0  \n",
            "137_Encoder.layer4.2.ReLU_relu                            -              -  \n",
            "138_Encoder.layer4.2.Conv2d_conv3                  131.584k      31.45728M  \n",
            "139_Encoder.layer4.2.BatchNorm2d_batch_norm3         1.024k          512.0  \n",
            "140_Encoder.layer4.2.StochasticDepth_SD                   -              -  \n",
            "141_Encoder.layer4.2.ReLU_relu                            -              -  \n",
            "142_Encoder.layer4.3.Conv2d_conv1                  131.328k      31.45728M  \n",
            "143_Encoder.layer4.3.BatchNorm2d_batch_norm1          512.0          256.0  \n",
            "144_Encoder.layer4.3.ReLU_relu                            -              -  \n",
            "145_Encoder.layer4.3.Conv2d_conv2                   590.08k     141.55776M  \n",
            "146_Encoder.layer4.3.BatchNorm2d_batch_norm2          512.0          256.0  \n",
            "147_Encoder.layer4.3.ReLU_relu                            -              -  \n",
            "148_Encoder.layer4.3.Conv2d_conv3                  131.584k      31.45728M  \n",
            "149_Encoder.layer4.3.BatchNorm2d_batch_norm3         1.024k          512.0  \n",
            "150_Encoder.layer4.3.StochasticDepth_SD                   -              -  \n",
            "151_Encoder.layer4.3.ReLU_relu                            -              -  \n",
            "152_Encoder.layer4.4.Conv2d_conv1                  131.328k      31.45728M  \n",
            "153_Encoder.layer4.4.BatchNorm2d_batch_norm1          512.0          256.0  \n",
            "154_Encoder.layer4.4.ReLU_relu                            -              -  \n",
            "155_Encoder.layer4.4.Conv2d_conv2                   590.08k     141.55776M  \n",
            "156_Encoder.layer4.4.BatchNorm2d_batch_norm2          512.0          256.0  \n",
            "157_Encoder.layer4.4.ReLU_relu                            -              -  \n",
            "158_Encoder.layer4.4.Conv2d_conv3                  131.584k      31.45728M  \n",
            "159_Encoder.layer4.4.BatchNorm2d_batch_norm3         1.024k          512.0  \n",
            "160_Encoder.layer4.4.StochasticDepth_SD                   -              -  \n",
            "161_Encoder.layer4.4.ReLU_relu                            -              -  \n",
            "162_reparam.Linear_fc1                             262.656k       262.144k  \n",
            "163_reparam.Linear_fc_mu                           262.656k       262.144k  \n",
            "164_reparam.Linear_fc_log_var                      262.656k       262.144k  \n",
            "165_reparam.Linear_fc2                             262.656k       262.144k  \n",
            "166_Decoder.ConvTranspose2d_dec1                 18.874624M   2.717908992G  \n",
            "167_Decoder.ConvTranspose2d_dec2                  7.471232M  17.213423616G  \n",
            "168_Decoder.ConvTranspose2d_dec3                   1.86784M     6.7239936G  \n",
            "169_Decoder.ConvTranspose2d_dec4                   131.104k     1.8874368G  \n",
            "170_Decoder.ConvTranspose2d_dec5                    32.784k     1.8874368G  \n",
            "171_Decoder.ConvTranspose2d_dec6                       8.2k     1.8874368G  \n",
            "172_Decoder.ConvTranspose2d_dec7                      219.0       49.7664M  \n",
            "-----------------------------------------------------------------------------------------------------------------\n",
            "                             Totals\n",
            "Total params             39.100563M\n",
            "Trainable params         39.100563M\n",
            "Non-trainable params            0.0\n",
            "Mult-Adds             42.368521664G\n",
            "=================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache\n",
        "gc.collect()\n",
        "import torchsummaryX\n",
        "x = torch.rand(batch_size,image_channels,640,360)\n",
        "torchsummaryX.summary(model,x.to(device))\n",
        "torch.cuda.empty_cache\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8tZBpEf-E3JV"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, dataset, device, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    counter = 0\n",
        "    for i, data in tqdm(enumerate(dataloader), total=int(len(dataset)/dataloader.batch_size)):\n",
        "        counter += 1\n",
        "        data = data[0]\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          reconstruction, mu, logvar = model(data)\n",
        "          bce_loss = criterion(reconstruction, data)\n",
        "          loss = final_loss(bce_loss, mu, logvar)\n",
        "        scaler.scale(loss).backward()\n",
        "        running_loss += loss.item()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "    train_loss = running_loss / counter\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xuNlzU9SE5LI"
      },
      "outputs": [],
      "source": [
        "def validate(model, dataloader, dataset, device, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(dataloader), total=int(len(dataset)/dataloader.batch_size)):\n",
        "            counter += 1\n",
        "            data= data[0]\n",
        "            data = data.to(device)\n",
        "            reconstruction, mu, logvar = model(data)\n",
        "            bce_loss = criterion(reconstruction, data)\n",
        "            loss = final_loss(bce_loss, mu, logvar)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # save the last batch input and output of every epoch\n",
        "            if i == int(len(dataset)/dataloader.batch_size) - 1:\n",
        "                recon_images = reconstruction\n",
        "    val_loss = running_loss / counter\n",
        "    return val_loss, recon_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ERddNO2rCm--"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLSiM7PMKfDD",
        "outputId": "d7de30d7-7763-42a7-8777-6431a7fb95ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key=\"3f0b6be3fb07a79b74df1d0e01feedb867a1acfb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "BDuC_SSPKipp",
        "outputId": "db46dc60-d017-4192-85c5-b14686fd0190"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msjudson\u001b[0m (\u001b[33mlearning_in_the_deep\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231211_001301-tk8aftsf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/learning_in_the_deep/project_ablation/runs/tk8aftsf' target=\"_blank\">CVAE_Resnet_12M_SGD_MSE_mean_reduction_augnmentations</a></strong> to <a href='https://wandb.ai/learning_in_the_deep/project_ablation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/learning_in_the_deep/project_ablation' target=\"_blank\">https://wandb.ai/learning_in_the_deep/project_ablation</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/learning_in_the_deep/project_ablation/runs/tk8aftsf' target=\"_blank\">https://wandb.ai/learning_in_the_deep/project_ablation/runs/tk8aftsf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = \"CVAE_Resnet_12M_SGD_MSE_mean_reduction_augnmentations\", ## Wandb creates random run names if you skip this field\n",
        "    #reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    id = \"tk8aftsf\",# Insert specific run id here if you want to resume a previous run\n",
        "    resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"project_ablation\" ### Project should be created in your wandb account\n",
        "    #config = config ### Wandb Config for your run\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm9jEh7HCoxo",
        "outputId": "75c57374-0e59-4448-9ca1-d8e343100b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [34:00,  2.33s/it]\n",
            "100%|██████████| 57/57 [02:04<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3779\n",
            "Val Loss: 4.4821\n",
            "Saving model\n",
            "Epoch 2 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:48,  2.31s/it]\n",
            "100%|██████████| 57/57 [02:01<00:00,  2.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9890\n",
            "Val Loss: 0.7234\n",
            "Saving model\n",
            "Epoch 3 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:14,  2.27s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8376\n",
            "Val Loss: 0.8319\n",
            "Saving model\n",
            "Epoch 4 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:23,  2.28s/it]\n",
            "100%|██████████| 57/57 [02:04<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7336\n",
            "Val Loss: 0.6503\n",
            "Saving model\n",
            "Epoch 5 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:43,  2.31s/it]\n",
            "100%|██████████| 57/57 [02:03<00:00,  2.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6620\n",
            "Val Loss: 1.7711\n",
            "Saving model\n",
            "Epoch 6 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:58,  2.26s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6010\n",
            "Val Loss: 0.4858\n",
            "Saving model\n",
            "Epoch 7 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:43,  2.24s/it]\n",
            "100%|██████████| 57/57 [01:58<00:00,  2.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5610\n",
            "Val Loss: 0.5226\n",
            "Saving model\n",
            "Epoch 8 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:22,  2.21s/it]\n",
            "100%|██████████| 57/57 [01:57<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5344\n",
            "Val Loss: 0.6777\n",
            "Saving model\n",
            "Epoch 9 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:48,  2.24s/it]\n",
            "100%|██████████| 57/57 [02:04<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5089\n",
            "Val Loss: 0.4875\n",
            "Saving model\n",
            "Epoch 10 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:16,  2.28s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4915\n",
            "Val Loss: 0.4478\n",
            "Saving model\n",
            "Epoch 11 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:26,  2.29s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4790\n",
            "Val Loss: 0.4526\n",
            "Saving model\n",
            "Epoch 12 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:50,  2.25s/it]\n",
            "100%|██████████| 57/57 [01:58<00:00,  2.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4601\n",
            "Val Loss: 0.4250\n",
            "Saving model\n",
            "Epoch 13 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:47,  2.24s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4545\n",
            "Val Loss: 0.4867\n",
            "Saving model\n",
            "Epoch 14 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:55,  2.25s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4383\n",
            "Val Loss: 0.4347\n",
            "Saving model\n",
            "Epoch 15 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:11,  2.27s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4265\n",
            "Val Loss: 0.5564\n",
            "Saving model\n",
            "Epoch 16 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:08,  2.27s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4156\n",
            "Val Loss: 0.3917\n",
            "Saving model\n",
            "Epoch 17 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:09,  2.27s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4194\n",
            "Val Loss: 0.3690\n",
            "Epoch 18 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:34,  2.30s/it]\n",
            "100%|██████████| 57/57 [02:01<00:00,  2.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4007\n",
            "Val Loss: 0.5162\n",
            "Saving model\n",
            "Epoch 19 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:36,  2.30s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3988\n",
            "Val Loss: 0.3440\n",
            "Saving model\n",
            "Epoch 20 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:18,  2.28s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3932\n",
            "Val Loss: 0.3867\n",
            "Saving model\n",
            "Epoch 21 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:19,  2.28s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3910\n",
            "Val Loss: 0.5245\n",
            "Saving model\n",
            "Epoch 22 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:19,  2.28s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3848\n",
            "Val Loss: 0.3711\n",
            "Saving model\n",
            "Epoch 23 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:39,  2.30s/it]\n",
            "100%|██████████| 57/57 [02:01<00:00,  2.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3771\n",
            "Val Loss: 0.3397\n",
            "Saving model\n",
            "Epoch 24 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:39,  2.30s/it]\n",
            "100%|██████████| 57/57 [02:01<00:00,  2.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3773\n",
            "Val Loss: 0.3466\n",
            "Epoch 25 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:56,  2.25s/it]\n",
            "100%|██████████| 57/57 [02:01<00:00,  2.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3682\n",
            "Val Loss: 0.3623\n",
            "Saving model\n",
            "Epoch 26 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:33,  2.30s/it]\n",
            "100%|██████████| 57/57 [01:59<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3743\n",
            "Val Loss: 0.3687\n",
            "Epoch 27 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:44,  2.31s/it]\n",
            "100%|██████████| 57/57 [02:02<00:00,  2.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3691\n",
            "Val Loss: 0.3418\n",
            "Epoch 28 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:33,  2.30s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3657\n",
            "Val Loss: 0.3441\n",
            "Saving model\n",
            "Epoch 29 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:18,  2.28s/it]\n",
            "100%|██████████| 57/57 [01:56<00:00,  2.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3638\n",
            "Val Loss: 0.3428\n",
            "Saving model\n",
            "Epoch 30 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:54,  2.25s/it]\n",
            "100%|██████████| 57/57 [02:00<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3627\n",
            "Val Loss: 0.3409\n",
            "Saving model\n",
            "Epoch 31 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [33:21,  2.28s/it]\n",
            "100%|██████████| 57/57 [01:58<00:00,  2.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3583\n",
            "Val Loss: 0.3314\n",
            "Saving model\n",
            "Epoch 32 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:50,  2.25s/it]\n",
            "100%|██████████| 57/57 [01:56<00:00,  2.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3590\n",
            "Val Loss: 0.3583\n",
            "Epoch 33 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [31:34,  2.16s/it]\n",
            "100%|██████████| 57/57 [01:53<00:00,  1.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3544\n",
            "Val Loss: 0.3155\n",
            "Saving model\n",
            "Epoch 34 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:52,  2.25s/it]\n",
            "100%|██████████| 57/57 [01:54<00:00,  2.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3552\n",
            "Val Loss: 0.3426\n",
            "Epoch 35 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [31:55,  2.18s/it]\n",
            "100%|██████████| 57/57 [01:56<00:00,  2.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3533\n",
            "Val Loss: 0.3163\n",
            "Saving model\n",
            "Epoch 36 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:28,  2.22s/it]\n",
            "100%|██████████| 57/57 [01:56<00:00,  2.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3505\n",
            "Val Loss: 0.3032\n",
            "Saving model\n",
            "Epoch 37 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:26,  2.22s/it]\n",
            "100%|██████████| 57/57 [01:57<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3558\n",
            "Val Loss: 0.3205\n",
            "Epoch 38 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [32:25,  2.22s/it]\n",
            "100%|██████████| 57/57 [01:57<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3467\n",
            "Val Loss: 0.3373\n",
            "Saving model\n",
            "Epoch 39 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [34:41,  2.37s/it]\n",
            "100%|██████████| 57/57 [01:57<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3476\n",
            "Val Loss: 0.3056\n",
            "Epoch 40 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [31:36,  2.16s/it]\n",
            "100%|██████████| 57/57 [01:55<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3451\n",
            "Val Loss: 0.3050\n",
            "Saving model\n",
            "Epoch 41 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [31:47,  2.17s/it]\n",
            "100%|██████████| 57/57 [01:55<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3441\n",
            "Val Loss: 0.3105\n",
            "Saving model\n",
            "Epoch 42 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "877it [31:45,  2.17s/it]\n",
            "100%|██████████| 57/57 [01:55<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3453\n",
            "Val Loss: 0.2922\n",
            "Epoch 43 of 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 292/876 [10:38<20:47,  2.14s/it]"
          ]
        }
      ],
      "source": [
        "from math import inf\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "lowest_train_loss = 1e7\n",
        "#wandb.watch(model, log=\"all\")\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss = train(\n",
        "        model, trainloader, trainset, device, optimizer, criterion\n",
        "    )\n",
        "    valid_epoch_loss, recon_images = validate(\n",
        "        model, testloader, testset, device, criterion\n",
        "    )\n",
        "    #train_loss.append(train_epoch_loss)\n",
        "    #valid_loss.append(valid_epoch_loss)\n",
        "    # save the reconstructed images from the validation loop\n",
        "    save_reconstructed_images(recon_images, epoch+1)\n",
        "    # convert the reconstructed images to PyTorch image grid format\n",
        "    image_grid = make_grid(recon_images.detach().cpu())\n",
        "    grid_images.append(image_grid)\n",
        "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
        "    print(f\"Val Loss: {valid_epoch_loss:.4f}\")\n",
        "    #wandb.log({\"train_loss\":train_epoch_loss,'validation_loss': valid_epoch_loss})\n",
        "    if train_epoch_loss < lowest_train_loss:\n",
        "      lowest_train_loss = train_epoch_loss\n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_encoder_state_dict':model.Encoder.state_dict(),\n",
        "                  'optimizer_state_dict':optimizer.state_dict(),\n",
        "                  'epoch': epoch}, './ModelEncoder')\n",
        "\n",
        "      torch.save({'model_decoder_state_dict':model.Decoder.state_dict(),\n",
        "                  'optimizer_state_dict':optimizer.state_dict(),\n",
        "                  'epoch': epoch}, './ModelDecoder')\n",
        "\n",
        "      torch.save({'model_reparam_state_dict':model.reparam.state_dict(),\n",
        "                  'optimizer_state_dict':optimizer.state_dict(),\n",
        "                  'epoch': epoch}, './ModelReparam')\n",
        "\n",
        "      wandb.save('./checkpoint.pth')\n",
        "      # Creating Artifact\n",
        "\n",
        "      model_artifact = wandb.Artifact(\"CVAE2.0\", type='model')\n",
        "\n",
        "        # Adding model file to Artifact\n",
        "\n",
        "      model_artifact.add_file(\"./Model\")\n",
        "\n",
        "        # Saving Artifact to WandB\n",
        "\n",
        "      run.log_artifact(model_artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk9bFkqTG6sR"
      },
      "outputs": [],
      "source": [
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-huG2jEWw7t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
